# **Bio_Especulaci√≥n üçÅüå¥ü™¥üê´üêëüê¶‚Äçüî•ü¶éü¶†üå≤ü™¥**

### Requerimientos 

* una cuenta de [**Gmail**](https://mail.google.com/mail/u/0/#inbox) (Con m√°s dee 5 GB de espcio en el drive)

* Una cuenta de [**Hugging Face**](https://huggingface.co/)

* [**Token de Huging Face**](https://huggingface.co/settings/tokens)

* [**Python**](https://www.python.org/)

* [**Ffmpeg**](https://ffmpeg.org/)



## **Proceso de Fine - Tuning ‚öôÔ∏è**

üåã Descargar un lote de fotos de [**Biodiversidad en Colombia**](https://commons.wikimedia.org/wiki/Campaign:Biodiversidad_en_Colombia_2025) 
Elije las que m√°s te gusten, con las que quieras crear tus personajes espcultavos, _este sera el material con el que nuestro modelo de va entrenar para, es decir con el que va tomar como referencia para generar las imagenes_

Guardalas en una carpeta üóÇÔ∏è

> [**üõëNOTA**]  
> Minimo **10 Fotos** 

Lo recomendado es convertir las imagenes a un tama√±o homogeniozado, por ejemplo **500 x 500**, para hacer esto en lote, te recomendamos usar este [**Script Redimensionador**](https://github.com/Noisk8/Bio_Especulacion/Tools/Redimensionar.py) escrito en **python** que utiliza la libreria [**ffmpeg**](https://ffmpeg.org/) 


#### Linux üêß

~~~
wget https://github.com/Noisk8/Bio_Especulacion/Tools/Redimensionar.py

chmod +x Redimensionar.py
~~~


### Windows ü™ü





## Entrenamiento del Molde üßó‚Äç‚ôÄÔ∏è

> [**üõëNOTA**]  
> Antes de ejecutar el Notebook debes tener  varias cosas listas 
> * Crea una carpeta üóÇÔ∏è llamada **Dreambooth_Bio** en el drive
> * Guarda las imagenes redimensionadas en la carpeta üóÇÔ∏è llamada **Dreambooth_Bio** en el drive
> * Crea el token üìù  token de hugging face, el token debe de ser con persmisos de ecritura



## [**üìùNotebook**](https://colab.research.google.com/drive/1wtAYBG3Org3mpgXFheY24tf15yTWYOge?authuser=1#scrollTo=-8JWf-fxfGka)

### Configuraci√≥n Inicial
Montaje de Google Drive: El notebook comienza montando Google Drive para acceder a las im√°genes de entrenamiento.

Requisitos de Datos: Verifica la existencia de una carpeta llamada **Dreambooth_Bio** que debe contener al menos 10 im√°genes (**recomendado 20-50**).

### Instalaci√≥n de Dependencias
El notebook instala y configura varias bibliotecas clave:

**Diffusers:** Para modelos de difusi√≥n estable
**Transformers:** Para modelos de lenguaje y visi√≥n
**PEFT (Parameter-Efficient Fine-Tuning):** Para optimizaci√≥n de memoria
**Accelerate:** Para entrenamiento distribuido
**Otras dependencias:** PyTorch, NumPy, Pillow, etc.

### Proceso de Entrenamiento
**Modelo Base:** Utiliza un modelo base de Stable Diffusion
**T√©cnica de Fine-Tuning:** Implementa DreamBooth con LoRA (Low-Rank Adaptation) para un entrenamiento eficiente
**Preprocesamiento:**
Carga y preprocesa im√°genes de la carpeta de Drive
Aplica transformaciones y aumentos de datos

### Configuraci√≥n del Entrenamiento
**Hiperpar√°metros personalizables:**
N√∫mero de pasos de entrenamiento
Tasa de aprendizaje
Batch size
Configuraciones de **LoRA**

### Guardado del Modelo
El modelo entrenado se guarda en Google Drive
Incluye metadatos y configuraciones necesarias para inferencia

### Interfaz de Usuario
Interfaz intuitiva para:
Cargar el modelo entrenado
Generar im√°genes con prompts personalizados
Ajustar par√°metros de generaci√≥n

### Caracter√≠sticas T√©cnicas Avanzadas
**Optimizaci√≥n de Memoria:** Uso de LoRA para reducir el consumo de memoria
**Compatibilidad con GPU:** Configuraci√≥n autom√°tica para usar aceleraci√≥n por GPU
**Integraci√≥n con Hugging Face:** Para cargar modelos preentrenados y subir modelos personalizados

### Flujo de Trabajo

Preparaci√≥n de datos (im√°genes en Drive)
Configuraci√≥n del entorno
Entrenamiento del modelo
Validaci√≥n y prueba
Generaci√≥n de im√°genes con el modelo entrenado

Este notebook est√° dise√±ado para ser ejecutado en Google Colab con acceso a GPU, lo que permite a los usuarios sin hardware especializado entrenar sus propios modelos de generaci√≥n de im√°genes basados en sus conjuntos de datos personalizados.








